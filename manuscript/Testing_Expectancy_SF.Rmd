---
title: "Surprise! Low Testing Expectancy Moderates the Sans Forgetica Effect"
shorttitle: "Testing Expectancy and Sans Forgetica"
author: 
  - name          : "Jason Geller"
    affiliation   : "1,2"
    corresponding : yes    # Define only one corresponding author
    address       : "Rutgers University Center for Cognitive Science (RuCCS), 152 Frelinghuysen Road, Busch Campus, Piscataway, New Jersey 08854"
    email         : "jason.geller@ruccs.rutgers.edu"
    
  - name          : "Kelly A. Kane"
    affiliation   : "3"
affiliation:
  - id            : "1"
    institution   : "University of Iowa"
  - id            : "2"
    institution   : "Rutgers University Center for Cognitive Science"
  - id            : "3"
    institution   : "Glenville State College"

authornote: |
  Add complete departmental affiliations for each author here. Each new line herein must be indented, like this line.

  Enter author note here.

abstract:
  "Recent work examaining the mnemonic effects of Sans Forgetica has been mixed. A possible explanation for this is whether participants were told about an upcoming test or no: testing expectancy. Here we report two experimets investigating the role of testing expectancy using a yes/no recognition memory test (Experiment 1, *N* = 231) and a cued recall test (Experiment 2, *N* = 116). In Experiment 1, Sans Forgetica overall eliciated lower judgements of learning and longer study times, but Sans Forgetica only improved improved memory when there was low test expectancy (compared to high test expectancy). In Experiment 2, using only a low test expectancy design, we found a similar pattern of results to Experiment 1. That is, Sans Forgetia elicted lower JOLs and longer study times, and produced better cued recall. Herein we have shown that Sans Forgetica can produce mnenemonic benefits, but only when testing expectancy is low. Caution should be taken in intreprting these results, however. Not only was the effect size small, but low testing expetcnay is not educationally realistic. Echocing previous failures to replicating the Sans Forgetica effect, students wanting to remember more and forget less should stick to other desirable difficultues shown to enhance memory."
  
keywords          : "Disfluency"
wordcount         : "3500"

bibliography      : ["ref.bib"]

floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no

documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_pdf
---

```{r setup, include = FALSE}
library("papaja")
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```

The influential desirable difficulty principle suggests that making learning harder not easier, such as having students take a test over information previously studied, can have noticeable and lasting impacts on student achievement [@Bjork2011; see @Sotola2020 for a recent meta-analysis]. Recently, the concept of desirable difficulties has been extended to include subtle perceptual manipulations that are difficult to encode [e.g., atypical fonts, blurring, handwritten cursive; @Diemand-Yauan2011; @Yue2012; @Geller2018]. One such manipulation garnering increased attention is the Sans Forgetica typeface. Sans Forgetica is a typeface developed by a team of psychologists, graphic designers, and marketers, consisting of intermittent gaps and black-slanted letters [@Earp2018]. The disfluent perceptual characteristics of the typeface are purported to stave off forgetting and enhance learning. However, as the famous astronomer Carl Sagan once said, "Extraordinary claims require extraordinary evidence [@Sagan1980]. 

There is a growing evidence that perceptual disfluency manipulations are simply not desirable for learning (see for meta-anlyssi). Does the same hold true for Sans Forgetica? In two independent studies, @Taylor2020 and @Geller2020 set out to examine whether Sans Forgetica is *really* a desirable difficulty. In the first conceptual replications of the Sans Forgetica effect, @Taylor2020, found (in a sample of 882 people across 4 experiments) that while Sans Forgetica was perceived as more disfluent by participants (Experiment 1) there was no evidence that Sans Forgetica yielded a mnemonic boost in cued recall with highly related word pairs (Experiment 2) compared to a fluent typeface (Arial) or when learning simple prose passages (Experiments 3-4). Extending these findings, @Geller2020 conducted three pre-registered experiments with over 800 participants, and found, similar to @Taylor202, that Sans Forgetica does not enhance learning for weakly related word pairs (Experiment 1), a complex prose passage on ground water (Experiment 2), or when the type of test was changed to a recognition memory test (Experiment 3). Taken together, across two independent replication attempts, and over a 1000 participants, there is weak evidence for a Sans Forgetica memory effect.

Despite these findings, some evidence for the effectiveness of the Sans Forgetica typeface does exist. For instance, @Eskenazi2020 found that Sans Forgetica can enhance learning. Using eye-tracking, @Eskenazi2020 had participants learn the spelling and meaning for 15 low-frequency words each presented in the context of two sentences. Both orthographic discriminabity (i.e., choosing the correct spelling of a word) and semantic acquisition (i.e., retrieving the definition of a word) were assessed. The authors reported a memory benefit for both orthographic discrimnability and semantics for words presented in Sans Forgetica compared to a normal (Courier) typeface, but only for participants that were good spellers. 

The mixed findings suggest that the Sans Forgetica may be fickle, with positive effects potentially bounded by specific conditions. Probing into @Eskenazi2020, a critical difference between their study and @Taylor202 and @Geller2020, is testing expectancy.In @Eskenazi2020, they did did not tell their participants about the upcoming tests. Thus, one common design feature that may moderate whether we see a Sans Forgetica effect is high testing expectancy. @Eitel2016 posited that testing expectancy may be an important moderator of the perceptual disfluency effect. They reasoned that if the  disfluency effect arises because of deeper, more effortful, processing, telling participants about a memory test should eliminate the effect. This occurs because testing expectancy would  countervail the effects of perceptual disfluency by eliciting additional processing for both fluent and disfluent stimuli. In contrast, low testing expectancy is less likely to impact processing of individual items,leaving effects of processing difficulty intact. While  @Eitel2016 did not find evidence for this,@cogsci18-Geller, using a masking disfluency manipulation, demonstrated in a yes/no recognition memory test that indeed only under low testing expectancy does a disfluency effect occur. Given this, it is possible, then, that a Sans Forgetica effect might arise when participants have low test expectancy. 

# Experiment 1

Experiment 1 examined whether the positive effects of Sans Forgetica are moderated by testing expectancy. Using a yes/no recognition memory test, we manipulated testing expectancy by telling half the participants about the upcoming memory test while for the other half being surreptitious about the upcoming memory test.In addition, we collected aggregate judgments of learning (i.e., a subjective memory prediction about future memory performance taken after all items are studied) and study times. We preregistered that if participants were not told about a memory test we would see a memory boot for Sans Forgetica stimuli,but not if they were told about a memory test. For JOLs,we predicted that we would not see JOL differences as function of typeface or testing expectancy. In terms of reading times, we predicted we would see longer study times for Sans Forgetica, but only in the low testing expectancy condition. These predictions are based on @Geller2020 (Experiments 2 and 3). 
# Method

Sample size, experimental design, hypotheses, outcome measures, and analysis plan for Experiment 1 were can be found on the Open Science Framework (https://osf.io/wgp9d). All raw and summary data, materials, and  R scripts for pre-processing, analysis, and plotting can be found at https://osf.io/d2vy8/.

## Participants

We preregistered a sample size of 230. All participants were recruited through prolific (prolific.co), and completed the study on the Gorilla platform  [www.gorilla.sc; Anwyl-Irvine2020]. The sample size was based off a previous experiment (@Geller2020, Experiment 1), wherein they calculated power to detect a medium sized interaction effect (*d* = 0.35) using a similar design to the current study. After data collection had ended we had a total of 231 participants. Participants completed the experiment in return for U.S.$8.00 an hour.

### Materials

Stimuli were 188 single-word nouns taken from Geller et al. (2018). All words were from the English Lexicon Project database [@Balota2007]. Both word frequency (all words were high frequency; mean log HAL frequency = 9.2) and length (all words were four letters) were controlled. The full set of stimuli can be found at https://osf.io/dsxrc/.

### Design

Per our pre-registration, d', JOLs, and study times were analyzed with a 2 (Typeface: Arial vs. Sans Forgetica ) x 2 (Testing Expectancy: High vs. Low) mixed analysis of variance (ANOVA). 

### Procedure

Similar to @Geller2020 (Experiment 3), we presented all participants with 188 words, 94 at study (47 in each typeface condition) and 188 at test (94 old and 94 new). Words were counterbalanced across the typeface and study/test conditions, such that each word served equally often as a target and a foil in both typefaces across participants. This lead to the creation of 4 counterbalanced lists. Word order was completely randomized, such that Arial and Sans Forgetica words were randomly intermixed in the study phase, and Arial and Sans Forgetica old and new words were randomly intermixed in the test phase, with old words always presented in the same typeface at test as they were at study. 

The main difference between the current experiment and @Geller2020 (Experiment 3) is that participants were randomly assigned to one of two conditions: the high expectancy test condition or the low expectancy test condition. Interested readers can view the entire task including instructions for each condition by following these links (High Test Expectancy experiment https://gorilla.sc/openmaterials/72765; Low test expectancy experiment: https://gorilla.sc/openmaterials/116227). 

The experiment proper consisted of four phases: a study phase,JOL phase, distractor phase, and test phase. During the study phase, a fixation cross appeared at the center of the screen for 500 ms. The fixation cross was immediately replaced by a word in the same location. To continue to the next trial, participants pressed the continue button at the bottom of the screen. Each trial was self-paced. After the study phase, participants completed a short three-minute distractor task wherein they wrote down as many U.S. state capitals as they could. Afterward, participants took an old-new recognition test. During the test phase, a word appeared in the center of the screen that either had been presented during study (“old”) or had not been presented during study (“new”). Old words occurred in their original typeface, and following the counterbalancing procedure, each new word was presented in Arial typeface or Sans Forgetica typeface. For each word presented, participants chose from one of two boxes displayed on the screen: a box labeled “old” to indicate that they had studied the word during study, and a box labeled “new” to indicate they did not remember studying the word. Sans Forgetica Words stayed on the screen until participants gave an “old” or “new” response. All words were individually randomized for each participant during both the study and test phases. After the experiment, participants were debriefed. 


### Analytic Strategy

For both experiments, an alpha level of .05 is maintained.  A variation of Cohen’s *d*~avg~  and generalized eta-squared [$\eta_{g}^{2}$}; @Olejnik2003] are used as effect size measures. Alongside traditional analyses that utilize null hypothesis significance testing (NHST), we also report the Bayes factors (BFs) for reported null effects. A Bayes Factor  > = 3 will be deemed as moderate evidence for null; BF > =10 strong  evidence for the null. All data were analyzed in R (vers. 4.0.2; R Core Team, 2020), with models fit using the afex (vers. 0.27-2; @Singmann2020) and BayesFactor packages (vers. 0.9.12-4.2; @Morey2018). All figures were generated using ggplot2 (vers. 3.3.0; Wickham, 2006). 

## Results and Discussion

### Recognition Memory

Performance was examined with d', a memory sensitivity measure derived from signal detection theory [@Macmillan2005]. Hits or false alarms at ceiling or floor were changed to .99 or .01. Hits and false alarms along with sensitivity (d') can be seen in Figure 1. Participants that were told about a memory test had better discrimination than those not told about a memory test (0.88 vs. 0.72),*M* ~diff~ = 0.16,*F*(1, 229) = 4.11, $\eta_{g}^{2}$ = .014, p = .044. Individuals were better at discriminating target words presented in Sans Forgetica  than Arial (0.86 vs. 0.74),*M* ~diff~ = 0.12, *F*(1, 229) = 10.73, $\eta_{g}^{2}$ =.010, *p* = .001. This was qualified by an interaction between Test Expectancy and Typeface, *F*(1, 229) = 4.34, $\eta_{g}^{2}$ = .004, *p* = .038. Simple effects showed that individuals in the low expectancy group showed better recognition memory for words presented in Sans Forgetica font compared to Arial, *F*(1, 229) = 14.297, *p* < .001, *d* = 0.31. In the high test expectancy group, there were no d` differences between the two typefaces, *F*(1, 229) = 0.716, *p* = .398, BF~O1~ = 5.83. 


```{r, echo=FALSE, warning=FALSE}
library(janitor)
library(tidyverse)
library(here)
library(afex)
library(emmeans)
library(data.table)
library(cowplot)
```


```{r message=FALSE, warning=FALSE, echo=FALSE} 

setwd(here::here('SF_data', 'Gorilla_data_low'))

data=here::here('SF_data', 'Gorilla_data_low')  # path to data files

file_list=list.files(data, pattern=".csv") # list of data files
 
# read in all files
datasetlow <-
  do.call("rbind", lapply(file_list, FUN=function(files){
    
    for (i in 1:length(files)){ 
      if(file.exists(files[i])){
        message( "now processing:", files[i])
      }
    }
    fread(files, header=TRUE, sep=",", na.strings = "", fill=TRUE)})) #fread makes reading in files quick
#

```

```{r}
library(lubridate)

low<-datasetlow %>% 
  janitor::clean_names(.) %>% 
  dplyr::mutate(date=as.Date(utc_date)) %>%
  dplyr::filter(date=="08/06/2020" |date=="09/06/2020" , zone_type=="response_button_text")

#response as character
low$response<-as.character(low$response)

low$testexpect<-"low"


```

#High Testing Data Load
```{r}


setwd(here::here('SF_data', 'Gorilla_data_high'))

data=here::here('SF_data', 'Gorilla_data_high')  # path to data files

file_list=list.files(data, pattern=".csv") # list of data files
 
# read in all files
highdata <-
  do.call("rbind", lapply(file_list, FUN=function(files){
    
    for (i in 1:length(files)){ 
      if(file.exists(files[i])){
        message( "now processing:", files[i])
      }
    }
    fread(files, header=TRUE, sep=",", na.strings = "", fill=TRUE)})) #fread makes reading in files quick
#

```

```{r}
library(lubridate)
# a batch of Ss we run before preregistration that should not be included in the analysis
high <-highdata %>% 
  janitor::clean_names(.) %>% 
  dplyr::mutate(date=as.Date(utc_date)) %>%
  dplyr::filter(date=="08/06/2020" | date=="0009/07/2020" |date=="0010/07/2020" | date=="09/06/2020", zone_type=="response_button_text")

#response as character
high$response<-as.character(high$response)

high$testexpect<-"high"

```

#Combine 
```{r echo=FALSE, message=FALSE, warning=FALSE}

high_low<-rbind(high, low)

```

```{r echo=FALSE, message=FALSE, warning=FALSE}
#response as character

ex4=high_low %>% dplyr::mutate(condition1= dplyr::case_when( 
  condition == "SF" ~ "Sans Forgetica", 
  condition =="normal" ~  "Arial", 
), isold= dplyr::case_when (
  old_new== "old" ~ 1, 
  old_new== "new" ~ 0), 
sayold=dplyr::case_when( 
  response=="old"~ 1, 
  response=="new" ~ 0, 
  ))


#classic SDT for those wanting to compare
sdt <- ex4 %>% 
  dplyr::mutate(type = "hit",
         type = ifelse(isold==1 & sayold==0, "miss", type),
         type = ifelse(isold==0 & sayold==0, "cr", type),  # Correct rejection
         type = ifelse(isold==0 & sayold==1, "fa", type))  # False alarm
sdt <- sdt %>% 
  dplyr::group_by(participant_private_id, type, condition1, testexpect) %>% 
  dplyr::summarise(count = n()) %>% 
  tidyr::spread(type, count)  # Format data to one row per person

sdt <- sdt %>% 
  dplyr::group_by(participant_private_id, condition1, testexpect)%>%
  dplyr::mutate(hr = hit / (hit+miss),
         fa = fa / (fa+cr)) %>%
  dplyr::mutate(hr=case_when(
    is.na(hr) ~ 0.99,
    TRUE ~ hr), 
    fa=case_when(
      is.na(fa)  ~ 0.01,
    TRUE ~ fa),
     zhr=qnorm(hr), 
     zfa=qnorm(fa), 
    dprime = zhr-zfa) %>%
  ungroup()

sdt

```

```{r, echo=FALSE, warning=FALSE, message=FALSE}
source("https://gist.githubusercontent.com/benmarwick/2a1bb0133ff568cbe28d/raw/fb53bd97121f7f9ce947837ef1a4c65a73bffb3f/geom_flat_violin.R")
#set up raincloud params


sdt1=sdt  %>% select(participant_private_id, condition1, testexpect, hr, fa) %>% 
  pivot_longer(hr:fa, names_to="type") %>%
  dplyr::mutate(isold=case_when(type=="hr" ~ "Old", type=="fa" ~ "New"))

sdt1$isold<-factor(sdt1$isold, levels=c("Old", "New"))

sdt1$Condition<-factor(sdt1$condition1, levels=c("Arial", "Sans Forgetica"))


highlowaov=sdt  %>% select(participant_private_id, condition1, testexpect, dprime) %>%
  mutate(testexpect=ifelse(testexpect=="low", "Low Test Expectancy", "High Test Expectancy"))


#plot

fig1 <- ggplot(highlowaov,aes(x=condition1,y=dprime,fill=condition1))+ facet_grid(~testexpect) + 
  geom_flat_violin(position = position_nudge(x = .2, y = 0), alpha = .4,adjust=4)+
  geom_point(position=position_jitter(width = .15),size = 1, alpha = 0.2) + 
  geom_boxplot(aes(x = condition1, y = dprime),outlier.shape = NA,
               alpha = 0.3, width = .1, colour = "BLACK") +
  theme_cowplot() +
  scale_colour_brewer(palette = "Dark2")+
  scale_fill_brewer(palette = "Dark2") +
  labs(y = "Sensitivity(d')", x = "Typeface") + theme(legend.position = "none")


```

```{r, echo=FALSE, warning=FALSE, message=FALSE}
#ANOVA


a1 <- aov_ez("participant_private_id", "dprime", highlowaov, 
             between = c("testexpect"), within=c("condition1")) # mixed

summary(a1)


#sfgen_wsci=summarySEwithin(data = highlowaov, measurevar = "dprime",
 #                      withinvars = "condition1", betweenvars = "testexpect", idvar = "participant_private_id")


a1
```


```{r, echo=FALSE, warning=FALSE, message=FALSE}


sdt1 <- sdt1 %>%
    mutate(testexpect=ifelse(testexpect=="low", "Low Test Expectancy", "High Test Expectancy"))


fig1b <- ggplot(sdt1,aes(x=condition1,y=value,fill=condition1))+ facet_grid(~testexpect + isold) + 
  geom_flat_violin(position = position_nudge(x = .2, y = 0), alpha = .4,adjust=4)+
  geom_point(position=position_jitter(width = .15),size = 1, alpha = 0.2) + 
  geom_boxplot(aes(x = condition1, y = value),outlier.shape = NA,
               alpha = 0.3, width = .1, colour = "BLACK") +
  theme_cowplot() +
  scale_colour_brewer(palette = "Dark2")+
  scale_fill_brewer(palette = "Dark2") +
  labs(y = "Pr Saying Old", x = "Typeface") + theme(legend.position = "none")


#oldnew=brm(glmm2, data=ex3, family=bernoulli(link="identity"), prior=Priors, sample_prior = TRUE,  cores=6, inits = 0, control = list(adapt_delta = .9), iter=3000)



```

### JOLs

Seven participants did not provide JOls to each typeface. We did not analyze the data for those participants. Using the same model as above, participants in the high testing expectancy  gorup provided higher JOLs than those in the low testing group (), *F*(1,221) = 16.01, $\eta_{g}^{2}$ = .065, *p* < .001. Arial elicited higher JOls than Sans Forgetica (61.5 vs. 57.5), *M* ~diff~ = 4.0, *F*(1,221) = 27.05, $\eta_{g}^{2}$ = .004, *p* < .001. There was no interaction between Testing Expectancy and Typeface, *F*(1,221) = 0.13, $\eta_{g}^{2}$ < .001, *p* = .715. Compared to a main effects-only model, there was strong evidence for no interaction, BF~01~ = 7.28. 

```{r, echo=FALSE, warning=FALSE, message=FALSE}
#JOls

 #get Rts

jol_high<- highdata %>% 
  mutate(testexpect="high")

jol_low<-datasetlow %>%
  mutate(testexpect="low")

jol_high_low <- rbind(jol_high, jol_low)


jols<-jol_high_low %>% janitor::clean_names(.) %>% dplyr::mutate(date=as.Date(utc_date)) %>%  dplyr::filter(date=="08/06/2020" | date=="0009/07/2020"|date=="0010/07/2020" | date=="09/06/2020",  zone_type=="response_slider_endValue" | zone_type=="response_text_entry")

# get RTjols1

jols$response<-as.numeric(jols$response)


jols1<- jols %>%
  dplyr::select(participant_private_id, response, testexpect) %>%
  dplyr::mutate(cond=rep(1:2, 231), font=ifelse(cond==1, "SF", "A")) %>%
  tidyr::drop_na() %>% 
  dplyr::mutate(testexpect=ifelse(testexpect=="low", "Low Test Expectancy", "High Test Expectancy"), font=ifelse(font=="A", "Arial", "Sans Forgetica"))
  


figjol <- ggplot(jols1,aes(x=font,y=response,fill=font))+ facet_grid(~testexpect) + 
  geom_flat_violin(position = position_nudge(x = .2, y = 0), alpha = .4,adjust=4)+
  geom_point(position=position_jitter(width = .15),size = 1, alpha = 0.2) + 
  geom_boxplot(aes(x = font, y = response),outlier.shape = NA,
               alpha = 0.3, width = .1, colour = "BLACK") +
  theme_cowplot() +
  scale_colour_brewer(palette = "Dark2")+
  scale_fill_brewer(palette = "Dark2") +
  labs(y = "Judgements of Learning", x = "Typeface") + theme(legend.position = "none")



#6.67

```



```{r, echo=FALSE, warning=FALSE, message=FALSE, eval=FALSE}
a1 <- aov_ez("participant_private_id", "response", jols1, 
             between = c("testexpt"), within=c("font")) # mixed

summary(jolsfa)

jolfont=emmeans(a1, ~font)

joltestexpect= emmeans(a1, ~font)

```
### Study Times

Although not pre-registered, we excluded reaction times less than 200 ms and reaction times greater than 2.5 SD above the mean per condition for each participant. The outlier procedure removed ~3 % of the data. Given reactions times are notoriously positively skewed, we also log transformed the data (see Fig.1C for reaction time data) to better approximate a normal distribution. Evidence for Testing Expectancy influencing study times was inconclusive, *F*(1,229) = 1.97, $\eta_{g}^{2}$ = .008, *p* =  .162, BF = 1.822. Typeface did influence reading times. Log-transformed study times were higher for Sans Forgetica than Arial, *F*(1,229) = 30.91, $\eta_{g}^{2}$ = .001, *p* < .001. There was no interaction between Testing Expectancy and Typeface, *F*(1,229) = 1.10, $\eta_{g}^{2}$ < .001, *p* = .296. Compared to a main effects-only model, there was strong evidence that there was no interaction between Testing Expectancy and Typeface, BF~01~ = 5.25. 

## Dicussion

The results from Experiment1 are clear-cut. As predicted, memory sensitivity for Sans Forgetica was higher when testing expectancy was low, but not when testing expectancy was high. This suggests that one potential reason for the @Taylor2020 and @Geller2020 failure to replicate was high test expectancy. Telling participants about a test lead to deeper processing for both Sans Forgetica and Arial typefaces, reducing any benefit from the Sans Forgetica typeface. This replicates what @cogsci18-Geller found with a masking manipulation. We also found that participants gave lower JOLs to Sans Forgetica and had longer study times compared to Arial. These findings are inconsistent with the predictions pre-registered, and contradict the findings of @Geller2020 (Experiment 2) and @Taylor2020 (Experiment 1). In the current experiment, a within-subject manipulation of typeface was used whereas in @Geller2020 (Experiment 2) and @Taylor2020 used a between-subjects typeface manipulation.The finding of lower JOls to disfluent stimuli compared to more fluent stimuli is inline with other studies that used a within-participant manipulations (). In relation to study times, @Geller2020 did not study time differences between typefaces. To examine this further, in Experiment 2 we examine memory for Sans Forgetica in a cued recall task and collect JOLs and study times ti see if we can replicate the basic finding herein. 


```{r, echo=FALSE, warning=FALSE, message=FALSE}
datasetlow$testexpt<-"low"
highdata$testexpt<-"high"

rt_high_low <- rbind(datasetlow, highdata)

rt<-rt_high_low %>% janitor::clean_names(.) %>% mutate(date=as.Date(utc_date)) %>%  dplyr::filter(date=="08/06/2020" | date=="0009/07/2020"|date=="0010/07/2020" | date=="09/06/2020", zone_type=="continue_button", display=="study") 

# get RT
rt$reaction_time<-as.numeric(rt$reaction_time)

rt1<- rt %>% 
  dplyr::group_by(participant_private_id, condition, testexpt) %>% 
  dplyr::select(participant_private_id, condition, testexpt, reaction_time) %>%
  dplyr::mutate(sdabove = mean(reaction_time, na.rm=TRUE) +  2.5*sd(reaction_time, na.rm=TRUE)) %>%
    dplyr::filter(reaction_time > 150, reaction_time < sdabove) %>%
  dplyr::summarise(mean_rt= mean(log(reaction_time))) %>%
   mutate(testexpt=ifelse(testexpt=="low", "Low Test Expectancy", "High Test Expectancy"), font=ifelse(condition=="normal", "Arial", "Sans Forgetica")) %>%
  select(-condition)
  

figrt <- ggplot(rt1,aes(x=font,y=mean_rt,fill=condition))+ facet_grid(~testexpt) + 
  geom_flat_violin(position = position_nudge(x = .2, y = 0), alpha = .4,adjust=4)+
  geom_point(position=position_jitter(width = .15),size = 1, alpha = 0.2) + 
  geom_boxplot(aes(x = font, y = mean_rt),outlier.shape = NA,
               alpha = 0.3, width = .1, colour = "BLACK") +
  theme_cowplot() +
  scale_colour_brewer(palette = "Dark2")+
  scale_fill_brewer(palette = "Dark2") +
  labs(y = "log(Study Times/ms)", x = "Typeface") + theme(legend.position = "none")




#write.csv(rt2, file="rt_high_low.csv")

#ttestBF(x=rt2$normal, y=rt
```

```{r, echo=FALSE, warning=FALSE, message=FALSE}
a1 <- aov_ez("participant_private_id", "mean_rt", rt1, 
             between = c("testexpt"), within=c("condition")) # mixed

summary(a1)

```

```{r, fig.align="center", fig.cap="Raincloud plots (Allen et al., 2019) depicting raw data (dots), box plots, and half violin kernel desntiy plots.A.Memory sensitivity (d') as a function of Typeface and Testing Expectancy. B. Judgements of Learning as a function of Typeface and Test Expectany. C. Study times (log transformed) as a function of Typeface and Test Expextancy. Raincloud plots (Allen et al., 2019) depicting raw data (dots), box plots, and half violin kernelViolin plots represent the kernal density of avearge accuracy (black dots) with the mean (white dot)", fig.height=12, fig.width=10, message=FALSE, warning=FALSE, results="asis"}


fig2 <- plot_grid(
  fig1, figjol, figrt,
  labels = "AUTO", ncol= 1, nrow = 3
)

fig2 

```



# Experiment 2

## Methods

### Participants

One hundred and sixteen participants (*N* = 116) participated through Prolific for U.S. $2.43. All participants were native English speakers with normal or corrected-to-normal vision. A sensitivity analysis conducted with the R package pwr[@Champely2020] indicated that our sample size provided  90% power to detect a small effect size  (d = 0.16) or  larger. 

### Design

Cued recall accuracy, JOLs, and reading times to Typefaces (Sans Forgetica vs. Arial) with a paired *t*-test. 

### Materials and Procedure 

The materials were adopted from Taylor el al. (2020, Experkment 2). Twenty highly associated word paris, were used (taken from the University of Florida norms). 

Similar to Experiment 1, Experiment 2 consisted of four phases, and was administered online through the gorilla.sc platform. The entire experiment can be run by following the following link: https://gorilla.sc/openmaterials/116224. During phase 1, participants were presented with a series of 20 word pairs,  presented one at time.  Participants were told to press the continue button after they had read each word. Half of the word pairs were presented in
Sans Forgetica and half in Arial. We created two versions of the word pair list, so that each cue-target pair was presented in each typeface across participants.  All counterbalanced lists contained the same word pairs. In Phase 2, participants were presented with the same distractor task as Experiment 1. Finally, in the third phase of the experiment, participants’ memory for the word pairs was tested by presenting the first word of the pair they studied during phase 1 and asking them to type the second word of that pair into a box. We presented the memory test in a font not tied to the stud phase so as not to reinstate context at test. The cued words presented during Phase 1 were presented one-by-one, in a random order.


### Scoring

To score typed responses during the cued recall phase, we used the lrd package in R [@Maxwell2020]. The lrd package provides an automated way to score word responses. A partial match of 80% was used to determine whether a typed response was correct or not.


## Results and Discussion

### Cued Recall

With low testing expectancy, performance was better when words were presented in Sans Forgetica (47% vs. 42%), *M*~diff~ = 5%, *t*(115) = 2.363, *SE* =  0.046, *p* = .020, 95 CI% [0.008, 0.090], *d*~avg~ = 0.18. See fig 2a. 



```{r}

setwd(here::here("cue_recall", "gorilla_data"))

data=here::here("cue_recall", "gorilla_data") # path to data files

file_list=list.files(data, pattern=".csv") # list of data files
 
# read in all files
dataset <-
  do.call("rbind", lapply(file_list, FUN=function(files){
    
    for (i in 1:length(files)){ 
      if(file.exists(files[i])){
        message( "now processing:", files[i])
      }
    }
    fread(files, header=TRUE, sep=",", na.strings = "", fill=TRUE)})) #fread makes reading in files quick
#

```



```{r}
cued_fig <- read.csv(here::here("cue_recall", "summary_data", "cued", "dd_acc.csv"))


two.group.paired <- 
  cued_fig %>%
  pivot_longer(., a:sf, names_to="typeface", values_to="accuracy")%>%
  mutate(Typeface=case_when(typeface==
                               "a" ~ "Arial", 
                            typeface=="sf" ~ "Sans_Forgetica"
                             ), Typeface=as.factor(Typeface)) %>%
                             select(-typeface)%>%
          tidyr::pivot_wider(names_from=Typeface, values_from=accuracy)
          
          
          
# plot 


fig2a <- 
  cued_fig %>%
  pivot_longer(., a:sf, names_to="typeface", values_to="accuracy")%>%
  mutate(Typeface=case_when(typeface==
                               "a" ~ "Arial", 
                            typeface=="sf" ~ "Sans Forgetica"
                             ), Typeface=as.factor(Typeface)) %>%
  mutate(accuracy=accuracy*100)
      


source("https://gist.githubusercontent.com/benmarwick/2a1bb0133ff568cbe28d/raw/fb53bd97121f7f9ce947837ef1a4c65a73bffb3f/geom_flat_violin.R")
#set up raincloud params
raincloud_theme = theme(
text = element_text(size = 10),
axis.title.x = element_text(size = 16),
axis.title.y = element_text(size = 16),
axis.text = element_text(size = 14),
axis.text.x = element_text(angle = 45, vjust = 0.5),
legend.title=element_text(size=16),
legend.text=element_text(size=16),
legend.position = "right",
plot.title = element_text(lineheight=.8, face="bold", size = 16),
panel.border = element_blank(),
panel.grid.minor = element_blank(),
panel.grid.major = element_blank(),
axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'))


fig1a <- ggplot(fig2a,aes(x=Typeface,y=accuracy,fill=Typeface))+
  geom_flat_violin(position = position_nudge(x = .2, y = 0), alpha = .4,adjust=4)+
  geom_point(position=position_jitter(width = .15),size = 1, alpha = 0.4) + 
  geom_boxplot(aes(x = Typeface, y = accuracy),outlier.shape = NA,
               alpha = 0.3, width = .1, colour = "BLACK") +
  theme_cowplot() +
  scale_colour_brewer(palette = "Dark2")+
  scale_fill_brewer(palette = "Dark2") +
  labs(y = "Cued Recall Accuracy (Percent Correct)", x = "Typeface") + theme(legend.position = "none") 
```

### JOLs

Looking at particpants JOLs to each Typeface, Partcipants' JOLs were lower for Sans Forgetica than Arail  (65.83 vs. 70.84), *M* ~diff~ = -5.02, *t*(108) = -3.12, *SE* =  1.61, 95 CI% [0.030, 0.114], *p* = .002, *d*~avg~ = 0.15. See fig 2a.


```{r}
cued_jol <- read.csv(here("cue_recall", "summary_data", "jols", "cued_jols_summary.csv"))

two.group.pairedJOL <- 
  cued_jol %>%
  drop_na()%>%
  pivot_longer(., A:SF, names_to="typeface", values_to="JOLs")%>%
  mutate(Typeface=case_when(typeface==
                               "A" ~ "Arial", 
                            typeface=="SF" ~ "Sans Forgetica"              
                            )) 
                            
 #jol_wsci=summarySEwithin(data = two.group.pairedJOL, measurevar = "JOLs",
       #                withinvars = "Typeface", idvar = "participant_private_id")   
                       
    #                   
                       
                       
# fig


fig2b <- ggplot(two.group.pairedJOL,aes(x=Typeface,y=JOLs,fill=Typeface))+
  geom_flat_violin(position = position_nudge(x = .2, y = 0), alpha = .4,adjust=4)+
  geom_point(position=position_jitter(width = .15),size = 1, alpha = 0.4) + 
  geom_boxplot(aes(x = Typeface, y = JOLs),outlier.shape = NA,
               alpha = 0.3, width = .1, colour = "BLACK") +
  theme_cowplot() +
  scale_colour_brewer(palette = "Dark2")+
  scale_fill_brewer(palette = "Dark2") +
  labs(y = "Judgements of Learning", x = "Typeface") + theme(legend.position = "none")


                            

```

### Reaction Times

Similar to Experiment 1, we excluded reaction times less than 200 ms and reaction times greater than 2.5 SD above the mean per condition for each participant. The outlier procedure removed ~ 3% of the data. We also log transformed the data (see Fig.1C for reaction time data). A paired t-test on mean log RTs showed that reading times were larger for Sans Forgetica than Arial (7.58 vs. 7.51), *M* ~diff~ = 0.072,  t  = 3.40, *SE* =  236, *p* < .001, 95 CI% [0.030, 0.114], *d*~avg~ = 0.13.

```{r message=FALSE, warning=FALSE, show=FALSE}
#get Rts
rt<-dataset %>% janitor::clean_names(.) %>%  dplyr::filter(zone_type=="continue_button", display=="study") 

# get RT
rt$reaction_time<-as.numeric(rt$reaction_time)

rt1<- rt %>% 
  dplyr::group_by(participant_private_id, font) %>% 
  dplyr::select(participant_private_id, font, reaction_time) %>%
  dplyr::mutate(sdabove = mean(reaction_time, na.rm=TRUE) +  2.5*sd(reaction_time, na.rm=TRUE)) %>%
    dplyr::filter(reaction_time > 150, reaction_time < sdabove) %>%
  dplyr::summarise(mean_rt= mean(log(reaction_time))) %>%
  pivot_wider(names_from=font, values_from = "mean_rt")
  

# fig

rt1_fig <- rt %>% 
  dplyr::group_by(participant_private_id, font) %>% 
  dplyr::select(participant_private_id, font, reaction_time) %>%
  dplyr::mutate(sdabove = mean(reaction_time, na.rm=TRUE) +  2.5*sd(reaction_time, na.rm=TRUE)) %>%
    dplyr::filter(reaction_time > 150, reaction_time < sdabove) %>%
  dplyr::summarise(mean_rt= mean(log(reaction_time))) %>%
  mutate(font=ifelse(font=="a", "Arial", "Sans Forgetica"))
  
  
  
  fig2c <- ggplot(rt1_fig,aes(x=font,y=mean_rt,fill=font))+
  geom_flat_violin(position = position_nudge(x = .2, y = 0), alpha = .4,adjust=4)+
  geom_point(position=position_jitter(width = .15),size = 1, alpha = 0.4) + 
  geom_boxplot(aes(x = font, y = mean_rt),outlier.shape = NA,
               alpha = 0.3, width = .1, colour = "BLACK") +
  theme_cowplot() +
  scale_colour_brewer(palette = "Dark2")+
  scale_fill_brewer(palette = "Dark2") +
  labs(y = "log(Study Time)", x = "Typeface") + theme(legend.position = "none")

```


```{r, fig.align="center", fig.cap="Raincloud plots (Allen et al., 2019) depicting raw data (dots), box plots, and half violin kernel desntiy plots.A.Memory sensitivity (d') as a function of Typeface and Testing Expectancy. B. Judgements of Learning as a function of Typeface and Test Expectany. C. Study times (log transformed) as a function of Typeface and Test Expextancy. Raincloud plots (Allen et al., 2019) depicting raw data (dots), box plots, and half violin kernelViolin plots represent the kernal density of avearge accuracy (black dots) with the mean (white dot)", fig.height=12, fig.width=10, message=FALSE, warning=FALSE, results="asis"}

fig1 <- plot_grid(
  fig1a, fig2b, fig2c,
  labels = "AUTO", ncol= 2, nrow = 2
)

fig1

```


# General Discussion

Herein we have shown a boundary condition for the Sans Forgetica effect: testing expectancy. To summarize our findings, In Experiment 1 using a a recognition memory Sans Forgetica exerted a positive effect on memory when p were not told about upcoming memory test. In experiment 21 Similar to other perceptual disfluency manipulations (masking, handwritten cursive) sans forgetica seemed to be o jefgive

Contrary to Experiments 1-3, when testing expectancy was low, we observed better memory for materials in Sans Forgetica. This provides a potential boundary condition for the Sans Forgetica effect. That is, when testing expectancy is high (e.g., Experiments 1-3) we do not see a Sans Forgetica effect. However, we do when testing expectancy is low. This might offer a potential explanation for why there is mixed evidence on the effectiveness of Sans Forgetica to enhance memory [See @Eskenazi2020]. The results herein might explain why they did find a positive effect for Sans Forgetica in a subset of their participants. Despite this, given the small effect size and the fact that studying is almost always done intentionally, their is really no evidence that it should be used as a study tool. 

RTs (one possible is optimal study hypothesis switching from harder stimuli to stumuli they know). JOLs would contradict this. 

\newpage

# References
```{r create_r-references}
r_refs(file = "ref.bib")
```

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id = "refs"></div>
\endgroup
