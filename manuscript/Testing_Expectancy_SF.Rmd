---
title: "Surprise! Low Testing Expectancy Moderates the Sans Forgetica Effect" 
author: 
  - name          : "Jason Geller"
    affiliation   : "1,2"
    corresponding : yes    # Define only one corresponding author
    address       : "Postal address"
    email         : "jason.geller@ruccs.rutgers.edu"

affiliation:
  - id            : "1"
    institution   : "University of Iowa"
  - id            : "2"
    institution   : "Rutgers Center for Cognitive Science"

authornote: |
  Add complete departmental affiliations for each author here. Each new line herein must be indented, like this line.

  Enter author note here.

abstract: |
  One or two sentences providing a **basic introduction** to the field,  comprehensible to a scientist in any discipline.
  
  Two to three sentences of **more detailed background**, comprehensible  to scientists in related disciplines.
  
  One sentence clearly stating the **general problem** being addressed by  this particular study.
  
  One sentence summarizing the main result (with the words "**here we show**" or their equivalent).
  
  Two or three sentences explaining what the **main result** reveals in direct comparison to what was thought to be the case previously, or how the  main result adds to previous knowledge.
  
  One or two sentences to put the results into a more **general context**.
  
  Two or three sentences to provide a **broader perspective**, readily comprehensible to a scientist in any discipline.
  
  <!-- https://tinyurl.com/ybremelq -->
  
keywords          : "keywords"
wordcount         : "X"

bibliography      : ["ref.bib"]

floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no

documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_pdf
---

```{r setup, include = FALSE}
library("papaja")
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```

The highly influential desirable difficulty principle suggests that making learning harder not easier, such as having students engage in retrieval practice, can have noticeable and lasting impacts on student achievement [@Bjork2011; see @Sotola2020 for a recent meta-analysis]. Recently, the concept of desirable difficulties has been extended to include subtle perceptual manipulations that are difficult to encode [e.g., atypical fonts, blurring, handwritten cursive; @Diemand-Yauan2011; @Yue2012; @Geller2018]. One perceptual disfluency manipulation garnering increased attention from news outlets (NPR and Washington Post) and researchers alike is the Sans Forgetica typeface. Sans Forgetica is a typeface developed by a team of psychologists, graphic designers, and marketers, consisting of intermittent gaps and black-slanted letters [@Earp2017]. The perceptual characteristics of Sans Forgetica are purported to stave off forgetting and enhance learning. However, as Carl Sagan once said, "Extradionary claims require extradionary evidence.” []

In two independent attempts, @Taylor2020 and @Geller2020 set out to examine whether Sans Forgetica is *really* a desirable difficulty. In the first conceptual replications of the Sans Forgetica effect, @Taylor2020, found (in a sample of 882 people across 4 experiments) that while Sans Forgetica was perceived as more disfluent by participants (Experiment 1) there was no evidence that Sans Forgetica yielded a mnemonic boost in cued recall with highly related word pairs (Experiment 2) compared to a fluent typeface (Arial) or when learning simple prose passages (Experiments 3-4). Extending these findings, @Geller2020 conducted three pre-registered experiments with over 800 participants, and found, similar to @Taylor202, that Sans Forgetica does not enhance learning for weakly related word pairs (Experiment 1), a complex prose passage on ground water (Experiment 2), or when the type of test was changed to a recognition memory test (Experiment 3). Taken together, across two independent replication attempts, and over a 1000 participants, there is weak evidence for a Sans Forgetica memory effect.

Despite these findings, some evidence for the effectiveness of the Sans Forgetica typeface does exist. For instance, @Eskenazi2020 found that Sans Forgetica can enhance learning. Using eye-tracking, @Eskenazi2020 had participants learn the spelling and meaning for 15 low-frequency words each presented in the context of two sentences. Both orthographic discriminabity (i.e., choosing the correct spelling of a word) and semantic acquisition (i.e., retrieving the definition of a word) were assessed. The authors reported a memory benefit for both orthographic discrimnability and semantics for words presented in Sans Forgetica compared to a normal (Courier) typeface, but only for participants that were good spellers. 

The mixed findings suggest that the Sans Forgetica may be fickel, with positive effects potentially bounded by specific conditions. Probing into @Eskenazi2020, an important difference between their study and @Taylor202 and @Geller2020, is testing expectancy. In @Eskenazi2020, they did did not tell their participants about the upcoming orthographic and semantic discriminability test. Thus, one common design feature that may moderate whether we see a Sans Forgetica effect is high testing expectancy. Indeed, Eitel and Kuhl  (2016) posited that testing expectancy may be an important moderator of the perceptual disfluency effect. They reasoned that if the  disfluency effect arises  because of deeper, more  effortful, processing, telling participants about a  memory test should eliminate the effect. This occurs because testing expectancy  would  countervail the effects of perceptual disfluency by eliciting additional processing for both fluent and disfluent stimuli. In contrast, low testing expectancy is less likley to impact processing of individual items,leaving effects of processing difficulty intact. Whuile  Eitel  and Kuhl did not find evidence for this,  @cogsci18-Geller, using a masking disfluency manipulation, demonstrated in a yes/no recognition memory test that only under low testing expectancy did a disfluency effect occurr--high testing expectancy elicited no disfluency effect. Given this, it is possible, then, that a Sans Forgetica effect might arise when participants are not told about an upcoming memory test. 

# Experiment 1

Experiment 1 examined whether the positive effects of Sans Forgetica [as seen in @Eskenazi2020] were moderated by testing expectancy. Using a yes/no recognition memory test, we manipulated whether individuals were told about an upcoming memory test. In addition, we examined participants study times and judgments of learning (JOLs) to Sans Forgetica stimuli. We preregistered that the Sans Forgetica effect would be moderated by testing expectancy insofar when participants were not told about a memory test we would see  effect, but not if they were told about a mmeory test. I predicted that... 

# Method

Sample size, experimental design, hypotheses, outcome measures, and analysis plan for Experiment 1 were can be found on the Open Science Framework (https://osf.io/wgp9d). All raw and summary data, materials, and  R scripts for preprocessing, analysis, and plotting can be found at https://osf.io/d2vy8/.

## Participants

We preregistered a sample size of 230. All participants were recruited through prolific (prolific.co), and completed the study on the Gorilla platform  [www.gorilla.sc; Anwyl-Irvine2020]. The sample size was based off a previous experiment (@Geller2020, Experiment 1), wherein they calculated power to detect a medium sized interaction effect (*d* = 0.35) using a similar design to the current study. After data collection had ended we had a total of 231 participants. Participants completed the experiment in return for U.S.$8.00 an hour. No participants met our pre-registered exclusion criteria (i.e., did not complete the experiment, started the experiment multiple times, experienced technical problems, or reported familiarity with the stimuli). 

### Materials

Stimuli were 188 single-word nouns taken from Geller et al. (2018). All words were from the English Lexicon Project database [@Balota2007]. Both word frequency (all words were high frequency; mean log HAL frequency = 9.2) and length (all words were four letters) were controlled. The full set of stimuli can be found at https://osf.io/dsxrc/.

### Design and Procedure

Typeface (Sans Forgetica vs. Arial) was manipulated within subjects and Testing Expectancy (High vs. Low) was manipulated between subject. Therefore, we used a 2 by 2 mixed design. Similar to @Geller2020 (Experiment 3), we presented all participants with 188 words, 94 at study (47 in each typeface condition) and 188 at test (94 old and 94 new). Words were counterbalanced across the typeface and study/test conditions, such that each word served equally often as a target and a foil in both typefaces across participants. This lead to the creation of 4 counterbalanced lists. Word order was completely randomized, such that Arial and Sans Forgetica words were randomly intermixed in the study phase, and Arial and Sans Forgetica old and new words were randomly intermixed in the test phase, with old words always presented in the same typeface at test as they were at study. 

Participants were randomly assigned to one of two conditions: the High Expectancy test condition or Low Expectancy test condition. In the high expectancy condition, participants were persnted with the following instructions: "In this task you will be presented with words. Some of the words you see will be hard to read while others will be easier to read.  After you have read  each word, click on the continue button to go to the next one.  Your memory will be tested later,  so please do your best to remember each word. Please do not write down the words.". In the low expectancy condition participants were presented with the follwing instructions: "In this task you will be presented with words. Some of the words you see will be in a weird font while  others will be presented in a normal font.  After you have read  each word, click on the continue button to go to the next one". 

The experiment propoer consisted of a study phase, a distractor task, and a task phase. During the study phase, a fixation cross appeared at the center of the screen for 500 ms. The fixation cross was immediately replaced by a word in the same location. To continue to the next trial, participants pressed the continue button at the bottom of the screen. Each trial was self-paced. After the study phase, participants completed a short three-minute distractor task wherein they wrote down as many U.S. state capitals as they could. Afterward, participants took an old-new recognition test. During the test phase, a word appeared in the center of the screen that either had been presented during study (“old”) or had not been presented during study (“new”). Old words occurred in their original typeface, and following the counterbalancing procedure, each new word was presented in Arial typeface or Sans Forgetica typeface. For each word presented, participants chose from one of two boxes displayed on the screen: a box labeled “old” to indicate that they had studied the word during study, and a box labeled “new” to indicate they did not remember studying the word. Sans Forgetica Words stayed on the screen until participants gave an “old” or “new” response. All words were individually randomized for each participant during both the study and test phases. After the experiment, participants were debriefed. 


### Analytic Strategy

For both experiments, an alpha level of .05 is maintained. Cohen’s *d* and generalized eta-squared [$\eta_{g}^{2}$}; @Olejnik2003] are used as effect size measures. Alongside traditional analyses that utilize null hypothesis significance testing (NHST), we also report the Bayes factors (BFs) for reported null effects. A Bayes Factor  > = 3 will be deemed as moderate evidence for null; BF > =10 strong  evidence for the null. All data were analyzed in R (vers. 4.0.2; R Core Team, 2020), with models fit using the afex (vers. 0.27-2; Singmann et al., 2020) and BayesFactor packages (vers. 0.9.12-4.2; Morey & Rouder, 2018). All figures were generated using ggplot2 (vers. 3.3.0; Wickham, 2006). 

## Results and Discussion

### Recognition Memory

Per our pregreistation, sensitivity (d') as analyzed with a 2 (Typeface: Arial vs. Sans Forgetica ) x 2 (Testing Expextancy: High vs. Low) Mixed analysis of variance (ANOVA). There was no difference in cued recall between the Generation and Sans Forgetica groups, *F*(1, 230) = 0.19, $\eta_{g}^{2}$ <.001, p = .752. Individuals recalled more disfluent target words than fluency target words, *F*(1, 230) = 25.31, $\eta_{g}^{2}$ =.017, *p* < .001. This was qualified by an interaction between Fluency and Difficulty Type, *F*(1, 230) = 25.06, $\eta_{g}^{2}$ = .017, *p* < .001. A Bayesian ANOVA indicated strong evidence for the interaction model over the main effects model, BF~10~ > 100. As seen in Figure 2, the magnitude of the generation effect was larger than the Sans Forgetica effect, which was, in fact, negligible. 

```{r}
library(janitor)
library(here)
library(afex)
library(emmeans)
library(Rmisc)
library(data.table)
library(tidyr)
```


```{r}

setwd(here::here('SF_data', 'Gorilla_data_low'))

data=here::here('SF_data', 'Gorilla_data_low')  # path to data files

file_list=list.files(data, pattern=".csv") # list of data files
 
# read in all files
datasetlow <-
  do.call("rbind", lapply(file_list, FUN=function(files){
    
    for (i in 1:length(files)){ 
      if(file.exists(files[i])){
        message( "now processing:", files[i])
      }
    }
    fread(files, header=TRUE, sep=",", na.strings = "", fill=TRUE)})) #fread makes reading in files quick
#

```

```{r}
library(lubridate)

low<-datasetlow %>% 
  janitor::clean_names(.) %>% 
  dplyr::mutate(date=as.Date(utc_date)) %>%
  dplyr::filter(date=="08/06/2020" |date=="09/06/2020" , zone_type=="response_button_text")

#response as character
low$response<-as.character(low$response)

low$testexpect<-"low"


```

#High Testing Data Load
```{r}


setwd(here::here('SF_data', 'Gorilla_data_high'))

data=here::here('SF_data', 'Gorilla_data_high')  # path to data files

file_list=list.files(data, pattern=".csv") # list of data files
 
# read in all files
highdata <-
  do.call("rbind", lapply(file_list, FUN=function(files){
    
    for (i in 1:length(files)){ 
      if(file.exists(files[i])){
        message( "now processing:", files[i])
      }
    }
    fread(files, header=TRUE, sep=",", na.strings = "", fill=TRUE)})) #fread makes reading in files quick
#

```

```{r}
library(lubridate)
# a batch of Ss we run before preregistration that should not be included in the analysis
high <-highdata %>% 
  janitor::clean_names(.) %>% 
  mutate(date=as.Date(utc_date)) %>%
  dplyr::filter(date=="08/06/2020" | date=="0009/07/2020" |date=="0010/07/2020" | date=="09/06/2020", zone_type=="response_button_text")

#response as character
high$response<-as.character(high$response)

high$testexpect<-"high"

```

#Combine 
```{r}

high_low<-rbind(high, low)

```

```{r}
#get Rts

datasetlow$testexpt<-"low"
highdata$testexpt<-"high"

rt_high_low <- rbind(datasetlow, highdata)

rt<-rt_high_low %>% janitor::clean_names(.) %>%  dplyr::filter(zone_type=="continue_button", display=="study") 

# get RT
rt$reaction_time<-as.numeric(rt$reaction_time)

rt1<- rt %>% 
  dplyr::group_by(participant_private_id , condition, testexpt) %>% 
  dplyr::summarise(mean=mean(reaction_time, na.rm=TRUE))

rt2=rt1 %>% pivot_wider(names_from=condition, values_from = "mean")

write.csv(rt2, file="rt_high_low.csv")

#ttestBF(x=rt2$normal, y=rt2$SF, paired=TRUE, data=rt2)
#t.test(x=rt2$normal, y=rt2$SF, paired=TRUE, data=rt2)

#6.67
```


```{r}
#JOls

 #get Rts

jol_high_low <- rbind(datasetlow, highdata)

jols<-jol_high_low %>% janitor::clean_names(.) %>%  dplyr::filter(zone_type=="response_slider_endValue" | zone_type=="response_text_entry") 

# get RTjols1

jols$response<-as.numeric(jols$response)


jols1<- jols %>% 
  dplyr::select(participant_private_id, response, testexpt) %>%
  mutate(cond=rep(1:2, 327), font=ifelse(cond==1, "SF", "A")) %>%
  select(-cond)%>%
  pivot_wider(names_from="font", values_from="response")

jols1<-na.omit(jols1)

write.csv(jols1, file="low_high_jols.csv")

#6.67

```

```{r}
#response as character

ex4=high_low %>% mutate(condition1= case_when( 
  condition == "SF" ~ "Sans Forgetica", 
  condition =="normal" ~  "Arial", 
), isold= case_when (
  old_new== "old" ~ 1, 
  old_new== "new" ~ 0), 
sayold=case_when( 
  response=="old"~ 1, 
  response=="new" ~ 0, 
  ))



#classic SDT for those wanting to compare
sdt <- ex4 %>% 
  dplyr::mutate(type = "hit",
         type = ifelse(isold==1 & sayold==0, "miss", type),
         type = ifelse(isold==0 & sayold==0, "cr", type),  # Correct rejection
         type = ifelse(isold==0 & sayold==1, "fa", type))  # False alarm
sdt <- sdt %>% 
  dplyr::group_by(participant_private_id, type, condition1, testexpect) %>% 
  dplyr::summarise(count = n()) %>% 
  spread(type, count)  # Format data to one row per person

sdt <- sdt %>% 
  group_by(participant_private_id, condition1, testexpect)%>%
  dplyr::mutate(hr = hit / (hit+miss),
         fa = fa / (fa+cr)) %>%
  dplyr::mutate(hr=case_when(
    is.na(hr) ~ 0.99,
    TRUE ~ hr), 
    fa=case_when(
      is.na(fa)  ~ 0.01,
    TRUE ~ fa),
     zhr=qnorm(hr), 
     zfa=qnorm(fa), 
    dprime = zhr-zfa) %>%
  ungroup()

sdt

```

```{r}
sdt1=sdt  %>% select(participant_private_id, condition1, testexpect, hr, fa) %>% 
  pivot_longer(hr:fa, names_to="type") %>%
  dplyr::mutate(isold=case_when(type=="hr" ~ "Old", type=="fa" ~ "New"))

sdt1$isold<-factor(sdt1$isold, levels=c("Old", "New"))

sdt1$Condition<-factor(sdt1$condition1, levels=c("Sans Forgetica", "Arial"))


highlowaov=sdt  %>% select(participant_private_id, condition1, testexpect, dprime)


```

```{r}
#ANOVA


a1 <- aov_ez("participant_private_id", "dprime", highlowaov, 
             between = c("testexpect"), within=c("condition1")) # mixed

summary(a1)


sfgen_wsci=summarySEwithin(data = highlowaov, measurevar = "dprime",
                       withinvars = "condition1", betweenvars = "testexpect", idvar = "participant_private_id")


a1
```

```{r}
means <- sdt1 

oldnewsub=summarySEwithin(data = means, measurevar = "value",
                       withinvars = c("condition1", "isold","type"), betweenvars=c("testexpect"), idvar = "participant_private_id")
```


```{r}
library(see)
bold <- element_text(face = "bold", color = "black", size = 14) 

p1<- ggplot(means, aes(condition1, value, fill=condition1))+
  facet_grid(.~testexpect+isold) + 
  geom_violin() + 
  geom_jitter2(width=0.11, alpha=.5)+ 
  geom_line(data=oldnewsub,aes(y=value, group=1), size=1)+ 
  geom_pointrange(data=oldnewsub, aes(y=value, ymin=value-ci, ymax=value+ci), size=1, color="white")+ 
  theme_bw(base_size=14)+
  labs(y="Pr Saying Old", x="Font Type") + 
  theme(legend.position = "none") + 
  theme(axis.text=bold) 


#oldnew=brm(glmm2, data=ex3, family=bernoulli(link="identity"), prior=Priors, sample_prior = TRUE,  cores=6, inits = 0, control = list(adapt_delta = .9), iter=3000)

p1

```


```{r,  fig.width=8, fig.height=12}

sdt$condition1<-factor(sdt$condition1, levels=c("Arial", "Sans Forgetica"))


dsw=summarySEwithin(data = sdt, measurevar = "dprime",
                       withinvars = "condition1", betweenvars = "testexpect",  idvar = "participant_private_id")
 
 
 
p2<- ggplot(sdt, aes(condition1, dprime, fill=condition1))+
  geom_violin() + facet_grid(~testexpect) + 
  geom_jitter2(width=0.11, alpha=.5)+ 
  geom_line(data=dsw,aes(y=dprime, group=1), size=2)+ 
  geom_pointrange(data=dsw, aes(y=dprime, ymin=dprime-se, ymax=dprime+se), size=1, color="white")+ 
  theme_bw(base_size=14)+
  labs(y="Sensitivity (d')", x="Font Type") + 
  theme(legend.position = "none") + 
  theme(axis.text=bold)

p2


patchwork1= p1/ p2 
patchwork1 + plot_annotation(tag_levels = 'A')


```


### Reaction Times

Self-paced reading times for Sans Forgetica were longer than reading times for Arial, (*M* ~diff~ = 0.14), *t*(143) = 3.16, *SE* =  0.046, *p* = .002, *d* = 0.26. There was strong evidence for an effect, (BF~10~ = 10.55). 

### JOLs

There were no JOL differences between Sans Forgetica and Arial typefaces, *t*(141) = 0.220, *SE* = 1.634, *p* = .826, BF ~01~ = 11.11). 

# Experiment 2
### Participants

One hundred and forty four participants (*N* = 144) participated on Prolific for U.S. $2.43. All participants were native English speakers with normal or corrected-to-normal vision. A sensitivity analysis conducted with the R package pwr indicated that our sample size provided  90% power to detect a small effect size  (d = 0.16) or  larger. 

### Materials, Procedure, and Design
Experiment 4 was in all respects identical to Experiment 3,
except for the encoding instructions given to participants at the start. Participants were told that they would be reading words presented in different typefaces. No memory test was mentioned.

## Results and Discussion

### Recognition Memory

With intentional instructions, performance was better when words were presented in Sans Forgetica compared to Arial (*M* ~diff~ = 0.14), *t*(143) = 3.16, *SE* =  0.046, *p* = .002, *d* = 0.26. There was strong evidence for an effect, (BF~10~ = 10.55).2

### Reaction Times

Self-paced reading times for Sans Forgetica were longer than reading times for Arial, (*M* ~diff~ = 0.14), *t*(143) = 3.16, *SE* =  0.046, *p* = .002, *d* = 0.26. There was strong evidence for an effect, (BF~10~ = 10.55). 

### JOLs

There were no JOL differences between Sans Forgetica and Arial typefaces, *t*(141) = 0.220, *SE* = 1.634, *p* = .826, BF ~01~ = 11.11). 


Contrary to Experiments 1-3, when testing expectancy was low, we observed better memory for materials in Sans Forgetica. This provides a potential boundary condition for the Sans Forgetica effect. That is, when testing expectancy is high (e.g., Experiments 1-3) we do not see a Sans Forgetica effect. However, we do when testing expectancy is low. This might offer a potential explanation for why there is mixed evidence on the effectiveness of Sans Forgetica to enhance memory [See @Eskenazi2020]. Indeed, probing into @Eskenazi2020, it appears they did not tell their participants about the upcoming orthographic and semantic discriminability test. The results herein might explain why they did find a positive effect for Sans Forgetica in a subset of their participants. Despite this, given the small effect size and the fact that studying is almost always done intentionally, their is really no evidence that it should be used as a study tool. 


RTs (one possible is optimal study hypothesis switching from harder stimuli to stumuli they know). JOLs would contradict this. 


```{r echo=FALSE, fig.align="center", eval = FALSE, fig.cap="A. Mean proportions of “old” responses. Violin plots represent the kernal density of average probability (black dots) with the mean (white dot) and within-subject 95\\% CIs. B. Memory sensitivity (d'). Violin plots represent the kernal density of avearge accuracy (black dots) with the mean (white dot) and Cousineau-Morey within-subject 95\\% CIs.", fig.height=6, fig.width=8, message=FALSE, warning=FALSE, results="asis"}
#frecog=read_csv(here("Expt3_data", "expt3recog.csv"))
#oldnew=glmer(sayold~isold*condition1+(1+isold*condition1|Participant.Private.ID)+ (1+isold*condition1|Stims), data=sfrecog, family=binomial(link="probit"))

data=here::here('Expt4_data', 'expt4_data.csv')  
dd=read_csv(data)


ex4=dd %>% mutate(condition1= case_when( 
  condition == "SF" ~ "Sans Forgetica", 
  condition =="normal" ~  "Arial", 
), isold= case_when (
  old_new== "old" ~ 1, 
  old_new== "new" ~ 0), 
sayold=case_when( 
  response=="old"~ 1, 
  response=="new" ~ 0, 
  ))



#classic SDT for those wanting to compare
sdt <- ex4 %>% 
  dplyr::mutate(type = "hit",
         type = ifelse(isold==1 & sayold==0, "miss", type),
         type = ifelse(isold==0 & sayold==0, "cr", type),  # Correct rejection
         type = ifelse(isold==0 & sayold==1, "fa", type))  # False alarm
sdt <- sdt %>% 
  dplyr::group_by(participant_private_id, type, condition1) %>% 
  dplyr::summarise(count = n()) %>% 
  spread(type, count)  # Format data to one row per person

sdt <- sdt %>% 
  group_by(participant_private_id, condition1)%>%
  dplyr::mutate(hr = hit / (hit+miss),
         fa = fa / (fa+cr)) %>%
  dplyr::mutate(hr=case_when(
    is.na(hr) ~ 0.99,
    TRUE ~ hr), 
    fa=case_when(
      is.na(fa)  ~ 0.01,
    TRUE ~ fa),
     zhr=qnorm(hr), 
     zfa=qnorm(fa), 
    dprime = zhr-zfa) %>%
  ungroup()

sdt

sdt1=sdt  %>% select(participant_private_id, condition1, hr, fa) %>% 
  pivot_longer(hr:fa, names_to="type") %>%
  dplyr::mutate(isold=case_when(type=="hr" ~ "Old", type=="fa" ~ "New"))



sdt1$isold<-factor(sdt1$isold, levels=c("Old", "New"))

sdt1$Condition<-factor(sdt1$condition1, levels=c("Sans Forgetica", "Arial"))


dprimebf=sdt  %>% select(participant_private_id, condition1, dprime) %>%
  pivot_wider(names_from=condition1, values_from = dprime)


#paired ttest
a1 <- t.test(dprimebf$Arial,dprimebf$`Sans Forgetica`, paired=TRUE, data=dprimebf)

#Bayes Factor
dprimebf<-as.data.frame(dprimebf)

ttestBF(x=dprimebf$Arial, y=dprimebf$`Sans Forgetica`, paired=TRUE, data=dprimebf)

t.test(x=dprimebf$Arial, y=dprimebf$`Sans Forgetica`, paired=TRUE, data=dprimebf)
#BF=7.14

# path to data files


means <- sdt1 

means$Condition<-factor(means$Condition, levels=c("Sans Forgetica", "Arial"))



oldnewsub=summarySEwithin(data = means, measurevar = "value",
                       withinvars = c("Condition", "isold","type"), idvar = "participant_private_id")

bold <- element_text(face = "bold", color = "black", size = 14) 

p1<- ggplot(means, aes(Condition, value, fill=Condition))+
  facet_grid(~isold) + 
  geom_violin() + 
  geom_jitter2(width=0.11, alpha=.5)+ 
  geom_line(data=oldnewsub,aes(y=value, group=1), size=1)+ 
  geom_pointrange(data=oldnewsub, aes(y=value, ymin=value-ci, ymax=value+ci), size=1, color="white")+ 
  theme_bw(base_size=14)+
  labs(y="Pr Saying Old", x="Font Type") + 
  theme(legend.position = "none") + 
  theme(axis.text=bold) 


#oldnew=brm(glmm2, data=ex3, family=bernoulli(link="identity"), prior=Priors, sample_prior = TRUE,  cores=6, inits = 0, control = list(adapt_delta = .9), iter=3000)

p1

sdt$condition1<-factor(sdt$condition1, levels=c("Sans Forgetica", "Arial"))


dsw=summarySEwithin(data = sdt, measurevar = "dprime",
                       withinvars = "condition1", idvar = "participant_private_id")
 
 
 
p2<- ggplot(sdt, aes(condition1, dprime, fill=condition1))+
  geom_violin() + 
  geom_jitter2(width=0.11, alpha=.5)+ 
  geom_line(data=dsw,aes(y=dprime, group=1), size=1)+ 
  geom_pointrange(data=dsw, aes(y=dprime, ymin=dprime-ci, ymax=dprime+ci), size=1, color="white")+ 
  theme_bw(base_size=14)+
  labs(y="Sensitivity (d')", x="Font Type") + 
  theme(legend.position = "none") + 
  theme(axis.text=bold)

p2


patchwork1= p1/ p2 
patchwork1 + plot_annotation(tag_levels = 'A')


```



\newpage

# References
```{r create_r-references}
r_refs(file = "ref.bib")
```

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id = "refs"></div>
\endgroup
